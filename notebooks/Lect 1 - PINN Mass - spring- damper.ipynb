{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCgpgtSqTbvP"
   },
   "source": [
    "# PINNs para el sistema masa‚Äìresorte‚Äìamortiguador\n",
    "\n",
    "**Autor:** David Ortiz ‚Äî 2025\n",
    "\n",
    "Accede al trabajo fundacional de las PINNs [aqu√≠](https://www.sciencedirect.com/science/article/pii/S0021999118307125).\n",
    "\n",
    "Este tutorial est√° inspirado en [este workshop](https://github.com/benmoseley/harmonic-oscillator-pinn-workshop), desarrollado por Ben Moseley.\n",
    "\n",
    "### Introducci√≥n\n",
    "Las Redes Neuronales Informadas por la F√≠sica (PINNs) integran ecuaciones gobernantes directamente en la funci√≥n de p√©rdida mediante diferenciaci√≥n autom√°tica. Este enfoque reduce la dependencia de grandes vol√∫menes de datos y aporta coherencia f√≠sica a la soluci√≥n aprendida.  \n",
    "En esta actividad se aplican PINNs al modelo lineal cl√°sico **masa‚Äìresorte‚Äìamortiguador**, para el cual existe una soluci√≥n anal√≠tica conocida, lo que permite evaluar cuantitativamente el desempe√±o del m√©todo.\n",
    "\n",
    "### Objetivos de aprendizaje\n",
    "- Implementar una PINN desde cero en PyTorch para resolver el sistema masa‚Äìresorte‚Äìamortiguador siguiendo un esquema estructurado de seis etapas.  \n",
    "- Identificar y comprender los distintos t√©rminos de la funci√≥n de p√©rdida de una PINN, incluyendo el residuo de la EDO y las condiciones iniciales.  \n",
    "- Analizar el proceso de entrenamiento de una PINN y el uso de diferenciaci√≥n autom√°tica para calcular derivadas de la red neuronal.\n",
    "\n",
    "### Resumen de la actividad\n",
    "Se construye una PINN para el sistema masa‚Äìresorte‚Äìamortiguador siguiendo los seis pasos introducidos en el taller te√≥rico:\n",
    "\n",
    "<img src=\"../figures/pinns_new_scheme.png\" width=\"800\" height=\"400\">\n",
    "\n",
    "- (1) formular el modelo matem√°tico;  \n",
    "- (2) definir el dominio del problema;  \n",
    "- (3) implementar una ANN como aproximador de la soluci√≥n $x(t)$;  \n",
    "- (4) emplear diferenciaci√≥n autom√°tica para obtener derivadas;  \n",
    "- (5) dise√±ar la funci√≥n de p√©rdida con t√©rminos f√≠sicos (residuo de la EDO y condici√≥n inicial);  \n",
    "- (6) seleccionar y configurar un optimizador (Adam).\n",
    "\n",
    "Finalmente, se ejecuta el ciclo de entrenamiento y se comparan los resultados obtenidos con la soluci√≥n exacta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importamos funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy for numerical operations\n",
    "import numpy as np\n",
    "# Import PyTorch for building and training neural networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Import Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# Import the time module to time our training process\n",
    "import time\n",
    "# Ignore Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLwL3oIbTbvS",
    "outputId": "d732db5c-47d7-4528-8888-d66be1381707"
   },
   "outputs": [],
   "source": [
    "# Setup (device + plots)\n",
    "def get_device() -> str:\n",
    "    return \"cuda\" if torch.cuda.is_available() else \\\n",
    "           \"mps\"  if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def set_mpl_style(gray: str = \"#5c5c5c\") -> None:\n",
    "    mpl.rcParams.update({\n",
    "        \"image.cmap\": \"viridis\",\n",
    "        \"text.color\": gray, \"xtick.color\": gray, \"ytick.color\": gray,\n",
    "        \"axes.labelcolor\": gray, \"axes.edgecolor\": gray,\n",
    "        \"axes.spines.right\": False, \"axes.spines.top\": False,\n",
    "        \"axes.formatter.use_mathtext\": True, \"axes.unicode_minus\": False,\n",
    "        \"font.size\": 15, \"interactive\": False, \"font.family\": \"sans-serif\",\n",
    "        \"legend.loc\": \"best\", \"text.usetex\": False, \"mathtext.fontset\": \"stix\",\n",
    "    })\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using {device} device\")\n",
    "set_mpl_style()\n",
    "\n",
    "# Metrics\n",
    "def relative_l2_error(u_num: torch.Tensor, u_ref: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.norm(u_num - u_ref) / torch.norm(u_ref)\n",
    "\n",
    "# Util function to plot the solutions\n",
    "def plot_comparison(t, theta_true, theta_pred, loss):\n",
    "    t, u, u_hat = (\n",
    "        x.detach().cpu().numpy().ravel()\n",
    "        for x in (t, theta_true, theta_pred)\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    ax[0].plot(t, u, label=r'$\\theta(t)$ (numerical)')\n",
    "    ax[0].plot(t, u_hat, label=r'$\\theta_{\\mathrm{pred}}(t)$')\n",
    "    ax[0].set(title='Numerical vs Predicted',\n",
    "              xlabel=r'Time $(s)$', ylabel='Amplitude', ylim=(-1, 1.3))\n",
    "    ax[0].legend(frameon=False)\n",
    "\n",
    "    ax[1].plot(t, np.abs(u - u_hat))\n",
    "    ax[1].set(title='Absolute Difference',\n",
    "              xlabel=r'Time $(s)$',\n",
    "              ylabel=r'$|\\theta - \\theta_{\\mathrm{pred}}|$')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "    ax.plot(loss)\n",
    "    ax.set(title='Training Progress',\n",
    "           xlabel='Iteration', ylabel='Loss',\n",
    "           xscale='log', yscale='log')\n",
    "    ax.grid(True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modelo matem√°tico del sistema masa‚Äìresorte‚Äìamortiguador\n",
    "\n",
    "El sistema masa‚Äìresorte‚Äìamortiguador describe el movimiento de una masa $m$ unida a un resorte de constante el√°stica $k$ y a un elemento disipativo con coeficiente de amortiguamiento $c$. En ausencia de fuerzas externas, su ecuaci√≥n de movimiento est√° dada por:\n",
    "\n",
    "\\begin{equation*}\n",
    "m\\,\\ddot{x}(t) + c\\,\\dot{x}(t) + k\\,x(t) = 0\n",
    "\\end{equation*}\n",
    "\n",
    "donde $x(t)$ representa el desplazamiento de la masa respecto a su posici√≥n de equilibrio, $\\dot{x}(t)$ su velocidad y $\\ddot{x}(t)$ su aceleraci√≥n.\n",
    "\n",
    "Dividiendo la ecuaci√≥n por la masa $m$, se obtiene una forma normalizada que resulta m√°s conveniente para el an√°lisis:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\ddot{x}(t) + 2\\zeta\\omega_n\\,\\dot{x}(t) + \\omega_n^2\\,x(t) = 0\n",
    "\\end{equation*}\n",
    "\n",
    "donde se han introducido los par√°metros est√°ndar del sistema:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\omega_n = \\sqrt{\\frac{k}{m}} \\qquad \\text{frecuencia natural no amortiguada}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\zeta = \\frac{c}{2\\sqrt{km}} \\qquad \\text{raz√≥n de amortiguamiento adimensional}\n",
    "\\end{equation*}\n",
    "\n",
    "En lo que sigue, trabajaremos con esta formulaci√≥n normalizada y fijaremos valores espec√≠ficos para los par√°metros del sistema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dominio temporal\n",
    "T = 5.0        # tiempo total de simulaci√≥n\n",
    "x0 = 1.0       # Posici√≥n inicial \n",
    "v0 = 0.0       # velocidad incial\n",
    "wn = 5.0       # Frecuencia natural\n",
    "zeta = 0.2     # raz√≥n de amortiguamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definici√≥n del dominio temporal\n",
    "\n",
    "En esta etapa se define el dominio sobre el cual la PINN ser√° **entrenada** y **evaluada**. El tiempo $t$ se considera en el intervalo $[0, T]$ y se muestrea en un conjunto de puntos que actuar√°n como entradas de la red neuronal durante el entrenamiento.\n",
    "\n",
    "> **üí° Nota**  \n",
    "> Cada punto $t_i \\in [0, T]$, con $i = 1, \\dots, N_{\\text{sample}}$, se denomina **punto de colocaci√≥n**.  \n",
    "> Este t√©rmino proviene de la estrecha relaci√≥n entre las PINNs y los m√©todos num√©ricos de colocaci√≥n cl√°sicos.\n",
    "\n",
    "> **üí° Nota**  \n",
    "> Para evaluar correctamente el desempe√±o del modelo, es conveniente utilizar conjuntos de puntos distintos para entrenamiento y evaluaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_dominio_temporal(T, N_train=101, N_eval=1000):\n",
    "    \"\"\"Crea el dominio temporal para la PINN.\"\"\"\n",
    "    t_train = torch.linspace(0, T, N_train, \n",
    "                             device=device, \n",
    "                             requires_grad=True).view(-1, 1)  # entrenamiento\n",
    "    t_eval = torch.linspace(0, T, N_eval, \n",
    "                             device=device, \n",
    "                             requires_grad=True).view(-1, 1)  # evaluaci√≥n\n",
    "    return t_train, t_eval # dominio de evaluaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Red neuronal como aproximador de la soluci√≥n\n",
    "\n",
    "En esta etapa se define una red neuronal que act√∫a como un aproximador param√©trico de la soluci√≥n de la ecuaci√≥n diferencial. La funci√≥n desconocida $x(t)$ se reemplaza por una red neuronal dependiente de un conjunto de par√°metros $\\Theta$:\n",
    "\n",
    "$$\n",
    "x_{\\text{PINN}}(t; \\Theta) \\approx x_{\\text{real}}(t).\n",
    "$$\n",
    "\n",
    "Los par√°metros del modelo corresponden a los pesos y sesgos de cada capa de la red, que se agrupan como:\n",
    "\n",
    "$$\n",
    "\\Theta = \\{ W_i, b_i \\}_{i=1}^{L},\n",
    "$$\n",
    "\n",
    "donde $W_i$ y $b_i$ representan los pesos y sesgos de la capa $i$, respectivamente, y $L$ es el n√∫mero total de capas. Estos par√°metros se ajustan durante el entrenamiento con el objetivo de minimizar el error asociado al cumplimiento de la ecuaci√≥n f√≠sica.\n",
    "\n",
    "> **üí° Nota**  \n",
    "> En este ejercicio se utiliza un perceptr√≥n multicapa (MLP) con funciones de activaci√≥n *tanh* y una inicializaci√≥n de pesos basada en el esquema de Glorot. El n√∫mero de capas ocultas, el n√∫mero de neuronas por capa y la funci√≥n de activaci√≥n se denominan **hiperpar√°metros** de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network class with user defined layers and neurons\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, hlayers = [1, 10, 10, 1]):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(hlayers[:-2])):\n",
    "            layers.append(nn.Linear(hlayers[i], hlayers[i+1]))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(hlayers[-2], hlayers[-1]))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        \"\"\"Xavier Glorot parameter initialization of the Neural Network\n",
    "        \"\"\"\n",
    "        def init_normal(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight) # Xavier\n",
    "        self.apply(init_normal)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Diferenciaci√≥n autom√°tica en PyTorch\n",
    "\n",
    "Antes de continuar, es necesario establecer c√≥mo calcular derivadas de la salida de una red neuronal respecto a sus entradas. Para ello se utiliza la **diferenciaci√≥n autom√°tica** (*automatic differentiation* o *autodiff*), una t√©cnica que permite evaluar gradientes de forma eficiente y exacta aplicando sistem√°ticamente la regla de la cadena.\n",
    "\n",
    "En PyTorch, las operaciones realizadas sobre tensores se registran en un **grafo computacional din√°mico**. Este gr√°fico permite calcular derivadas de manera autom√°tica mediante un proceso de propagaci√≥n hacia atr√°s (*backpropagation*), lo que resulta fundamental para imponer ecuaciones diferenciales directamente sobre la salida de la red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util function to calculate tensor gradients with autodiff\n",
    "def grad(outputs, inputs):\n",
    "    \"\"\"Computes the partial derivative of an output with respect\n",
    "    to an input.\n",
    "    Args:\n",
    "        outputs: (N, 1) tensor\n",
    "        inputs: (N, D) tensor\n",
    "    \"\"\"\n",
    "    return torch.autograd.grad(outputs, inputs,\n",
    "                        grad_outputs=torch.ones_like(outputs),\n",
    "                        create_graph=True,\n",
    "                        )[0]\n",
    "\n",
    "\n",
    "# Definir tensor de entrada. Si queremos derivar c/r a x necesitamos inicializar con requires_grad=True\n",
    "x = torch.tensor([1.0, 2.0, 3.0], device=device, requires_grad=True).view(-1,1).float() # (N,1)\n",
    "\n",
    "# Calcular operaci√≥n que dependen de x\n",
    "y = x**2 # (N,1)  \n",
    "\n",
    "# Calcular derivadas c/r a x \n",
    "# grad es un wrapper de torch.autograd\n",
    "dy_dx = grad(y, x) \n",
    "\n",
    "# Calcular derivadas de orden superior\n",
    "d2y_dx2 = grad(dy_dx, x)  \n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"y = x^2:\", y)\n",
    "print(\"dy/dx:\", dy_dx)\n",
    "print(\"d^2y/dx^2:\", d2y_dx2)  \n",
    "\n",
    "# Esto tambi√©n funciona para redes neuronales\n",
    "# test_ANN = NeuralNetwork()\n",
    "\n",
    "# NNx = test_ANN(x)\n",
    "# dNNx_dx = grad(NNx, x)\n",
    "# print(\"NNx: \", dNNx_dx)\n",
    "# print(\"dNNx/dx:\", dNNx_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Funci√≥n de p√©rdida informada por la f√≠sica\n",
    "\n",
    "El entrenamiento de la PINN se basa en el modelo normalizado del sistema masa‚Äìresorte‚Äìamortiguador, caracterizado por la frecuencia natural $\\omega_n$ y la raz√≥n de amortiguamiento $\\zeta$:\n",
    "\n",
    "$$\n",
    "\\ddot{x}(t) + 2\\zeta\\omega_n\\,\\dot{x}(t) + \\omega_n^2 x(t) = 0.\n",
    "$$\n",
    "\n",
    "La soluci√≥n desconocida $x(t)$ se aproxima mediante la salida de la red neuronal $x_{\\text{PINN}}(t;\\Theta)$. A partir de esta aproximaci√≥n se define el **residuo f√≠sico** de la ecuaci√≥n diferencial y las **condiciones iniciales**:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_{\\text{ode}}(t;\\,x_{\\text{PINN}}) &=\n",
    "\\frac{d^2 x_{\\text{PINN}}}{dt^2}\n",
    "+ 2\\zeta\\omega_n \\frac{d x_{\\text{PINN}}}{dt}\n",
    "+ \\omega_n^2 x_{\\text{PINN}}, \\\\\n",
    "g_{\\text{ic}}(0;\\,x_{\\text{PINN}}) &=\n",
    "x_{\\text{PINN}}(0;\\Theta) - x_0, \\\\\n",
    "h_{\\text{ic}}(0;\\,x_{\\text{PINN}}) &=\n",
    "\\frac{d x_{\\text{PINN}}(0;\\Theta)}{dt} - v_0.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "La funci√≥n de p√©rdida total se construye como una combinaci√≥n ponderada de estos t√©rminos:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\Theta) =\n",
    "\\frac{\\lambda_1}{N}\\sum_i f_{\\text{ode}}(t_i;\\,x_{\\text{PINN}})^2\n",
    "+ \\lambda_2\\, g_{\\text{ic}}(0;\\,x_{\\text{PINN}})^2\n",
    "+ \\lambda_3\\, h_{\\text{ic}}(0;\\,x_{\\text{PINN}})^2.\n",
    "$$\n",
    "\n",
    "El entrenamiento de la PINN consiste en resolver el problema de optimizaci√≥n\n",
    "\n",
    "$$\n",
    "\\min_{\\Theta} \\; \\mathcal{L}(\\Theta),\n",
    "$$\n",
    "\n",
    "utilizando diferenciaci√≥n autom√°tica (`torch.autograd`) para evaluar las derivadas temporales de la red necesarias para el c√°lculo del residuo f√≠sico.\n",
    "\n",
    "> **üí° Nota**  \n",
    "> Si la funci√≥n de p√©rdida incluye √∫nicamente t√©rminos f√≠sicos, el esquema es *data-free*.  \n",
    "> Al incorporar t√©rminos asociados a datos observados, el enfoque pasa a ser *data-driven*.\n",
    "\n",
    "> **üí° Nota**  \n",
    "> En este marco, las condiciones iniciales (y de frontera, cuando existen) se imponen de manera d√©bil a trav√©s de la funci√≥n de p√©rdida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function (Mean Squared Error) for training the network\n",
    "MSE_func = nn.MSELoss()\n",
    "\n",
    "# derivatives of the ANN\n",
    "def PINNLoss(PINN, t_phys, wn, zeta, x0 = 1, v0 = 0,\n",
    "             lambda1 = 1, lambda2 = 1, lambda3 = 1):\n",
    "\n",
    "    t0 = torch.tensor(0., device=device, requires_grad=True).view(-1,1)\n",
    "\n",
    "    # ANN output, first and second derivatives\n",
    "    x_pinn_t = PINN(t_phys)\n",
    "    x_pinn_dt = grad(x_pinn_t, t_phys)\n",
    "    x_pinn_ddt = grad(x_pinn_dt, t_phys)\n",
    "    \n",
    "    f_ode = x_pinn_ddt + 2 * zeta * wn * x_pinn_dt + wn**2 * x_pinn_t\n",
    "    ODE_loss = lambda1 * MSE_func(f_ode, torch.zeros_like(f_ode)) \n",
    "    \n",
    "    g_ic = PINN(t0)\n",
    "    IC_loss = lambda2 * MSE_func(g_ic, torch.ones_like(g_ic)*x0)\n",
    "    \n",
    "    h_bc = grad(PINN(t0),t0)\n",
    "    BC_loss = lambda3 * MSE_func(h_bc, torch.ones_like(h_bc)*v0)\n",
    "    \n",
    "    return ODE_loss + IC_loss + BC_loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Definici√≥n del optimizador\n",
    "\n",
    "Una vez definida la funci√≥n de p√©rdida, se selecciona un optimizador para ajustar los par√°metros de la red neuronal $\\Theta = \\{W_i, b_i\\}$. El objetivo es minimizar la p√©rdida informada por la f√≠sica mediante un esquema de optimizaci√≥n iterativo:\n",
    "\n",
    "$$\n",
    "\\min_{\\Theta} \\mathcal{L}(\\Theta),\n",
    "\\qquad\n",
    "\\Theta^{k+1} = \\Theta^{k} - \\alpha \\nabla_{\\Theta} \\mathcal{L}(\\Theta^{k}).\n",
    "$$\n",
    "\n",
    "En esta etapa se utiliza el optimizador **Adam**, un m√©todo de descenso de gradiente adaptativo que ajusta din√°micamente la tasa de aprendizaje de cada par√°metro. Su combinaci√≥n de momento y escalado adaptativo de gradientes lo hace especialmente adecuado para el entrenamiento estable de PINNs.\n",
    "\n",
    "> **üí° Nota**  \n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinn_optimizer(pinn, lr = 0.01):\n",
    "\n",
    "    # Define an optimizer (Adam) for training the network\n",
    "    return optim.Adam(pinn.parameters(), lr=lr,\n",
    "                        betas= (0.99,0.999), eps = 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciclo de entrenamiento\n",
    "\n",
    "En esta etapa se ejecuta el proceso iterativo mediante el cual la PINN ajusta sus par√°metros $\\Theta = \\{W_i, b_i\\}$ para minimizar la funci√≥n de p√©rdida definida previamente. En cada √©poca (*epoch*), el modelo eval√∫a el residuo de la ecuaci√≥n diferencial y las condiciones iniciales en los puntos de colocaci√≥n $t_i \\in [0, T]$, y actualiza los par√°metros seg√∫n el gradiente de la p√©rdida:\n",
    "\n",
    "$$\n",
    "\\Theta \\leftarrow \\Theta - \\eta \\, \\nabla_\\Theta \\mathcal{L}(\\Theta).\n",
    "$$\n",
    "\n",
    "El entrenamiento contin√∫a hasta que la p√©rdida converge o deja de disminuir de forma apreciable. Una vez finalizado, la soluci√≥n aproximada $x_{\\text{PINN}}(t;\\Theta)$ se compara con la soluci√≥n exacta para evaluar la calidad del ajuste y la capacidad del modelo de capturar la din√°mica del sistema masa‚Äìresorte‚Äìamortiguador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n se presenta el c√≥digo completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# ETAPA 1: INFORMACI√ìN DEL MODELO F√çSICO\n",
    "#===============================================================================\n",
    "# Dominio temporal\n",
    "T = 5.0        # tiempo total de simulaci√≥n\n",
    "x0 = 1.0       # Posici√≥n inicial \n",
    "v0 = 0.0       # velocidad incial\n",
    "wn = 5.0  # Frecuencia natural\n",
    "zeta = 0.2     # raz√≥n de amortiguamiento\n",
    "\n",
    "#===============================================================================\n",
    "# ETAPA 2: DEFINICI√ìN DEL DOMINIO \n",
    "#===============================================================================\n",
    "# Creamos los tensores de tiempo para el entrenamiento y la evaluaci√≥n\n",
    "t_train, t_eval = crear_dominio_temporal(T)\n",
    "\n",
    "#===============================================================================\n",
    "# ETAPA 3: CREACI√ìN DE LA RED NEURONAL SURROGANTE \n",
    "#===============================================================================\n",
    "# Creamos la ANN\n",
    "torch.manual_seed(123)\n",
    "hidden_layers = [1, 30, 30, 30, 1]# Par√°metros de la \n",
    "\n",
    "# Create an instance of the neural network\n",
    "x_pinn = NeuralNetwork(hidden_layers).to(device)\n",
    "nparams = sum(p.numel() for p in x_pinn.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {nparams}')\n",
    "\n",
    "#==========================================================================\n",
    "# ETAPA 4 Y 5: DEFINICI√ìN DE LA FUNCI√ìN DE COSTO BASADA EN LA F√çSICA\n",
    "#==========================================================================\n",
    "# Define a loss function (Mean Squared Error) for training the network\n",
    "MSE_func = nn.MSELoss()\n",
    "\n",
    "# derivatives of the ANN\n",
    "def PINNLoss(PINN, t_phys, wn, zeta, x0 = 1, v0 = 0, \n",
    "             w1 = 1, w2 = 1, w3 = 1):\n",
    "\n",
    "    t0 = torch.tensor(0., device=device, requires_grad=True).view(-1,1)\n",
    "\n",
    "    # ANN output, first and second derivatives\n",
    "    x_pinn_t = PINN(t_phys)\n",
    "    x_pinn_dt = grad(x_pinn_t, t_phys)\n",
    "    x_pinn_ddt = grad(x_pinn_dt, t_phys)\n",
    "    \n",
    "    f_ode = x_pinn_ddt + 2 * zeta * wn * x_pinn_dt + wn**2 * x_pinn_t\n",
    "    ODE_loss = w1 * MSE_func(f_ode, torch.zeros_like(f_ode)) \n",
    "    \n",
    "    g_ic = PINN(t0)\n",
    "    IC_loss = w2 * MSE_func(g_ic, torch.ones_like(g_ic)*x0)\n",
    "    \n",
    "    h_bc = grad(PINN(t0),t0)\n",
    "    BC_loss = w3 * MSE_func(h_bc, torch.zeros_like(h_bc)*v0)\n",
    "    \n",
    "    return ODE_loss + IC_loss + BC_loss \n",
    "\n",
    "#==========================================================================\n",
    "# ETAPA 6: DEFINICI√ìN DEl OPTIMIZADOR\n",
    "#==========================================================================\n",
    "learning_rate = 0.01\n",
    "optimizer = pinn_optimizer(x_pinn, learning_rate)\n",
    "\n",
    "#==========================================================================\n",
    "# CICLO DE ENTRENAMIENTO\n",
    "#==========================================================================\n",
    "training_iter = 20000\n",
    "\n",
    "# Initialize a list to store the loss values\n",
    "loss_values_pinn = []\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the neural network\n",
    "for i in range(training_iter):\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "\n",
    "    # input x and predict based on x\n",
    "    loss = PINNLoss(x_pinn, t_train, wn, zeta)\n",
    "\n",
    "    # Append the current loss value to the list\n",
    "    loss_values_pinn.append(loss.item())\n",
    "\n",
    "    if i % 500 == 0:  # print every 100 iterations\n",
    "        print(f\"Iteration {i}: Loss {loss.item()}\")\n",
    "\n",
    "    loss.backward() # compute gradients (backpropagation)\n",
    "    optimizer.step() # update the ANN weigths\n",
    "\n",
    "# Stop the timer and calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaci√≥n\n",
    "\n",
    "El comportamiento del sistema depende de $\\zeta$:\n",
    "\n",
    "- **Subamortiguado** ($0 < \\zeta < 1$): el sistema oscila con frecuencia amortiguada  \n",
    "  \\begin{equation*}\n",
    "  \\omega_d = \\omega_n \\sqrt{1 - \\zeta^2}\n",
    "  \\end{equation*}\n",
    "\n",
    "  la soluci√≥n puede escribirse en t√©rminos de las condiciones iniciales $x(0)=x_0$ y $\\dot{x}(0)=v_0$:\n",
    "  \\begin{equation*}\n",
    "  x(t) = e^{-\\zeta \\omega_n t}\n",
    "  \\left[\n",
    "  x_0 \\cos(\\omega_d t) +\n",
    "  \\frac{v_0 + \\zeta \\omega_n x_0}{\\omega_d}\n",
    "  \\sin(\\omega_d t)\n",
    "  \\right]\n",
    "  \\end{equation*}\n",
    "\n",
    "Esta expresi√≥n servir√° como referencia para validar la soluci√≥n obtenida mediante la red neuronal informada por la f√≠sica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masa_resorte_general(t, x0, v0, omega_n, zeta):\n",
    "    \"\"\"\n",
    "    Soluci√≥n exacta x(t) del sistema masa-resorte-amortiguador:\n",
    "        x'' + 2*zeta*omega_n*x' + omega_n^2*x = 0\n",
    "    Incluye los tres reg√≠menes (sub, cr√≠tico y sobreamortiguado).\n",
    "    \"\"\"\n",
    "    t = np.array(t, dtype=float)\n",
    "\n",
    "    if 0 < zeta < 1:  # Subamortiguado\n",
    "        omega_d = omega_n * np.sqrt(1 - zeta**2)\n",
    "        x = np.exp(-zeta * omega_n * t) * (\n",
    "            x0 * np.cos(omega_d * t) +\n",
    "            (v0 + zeta * omega_n * x0) / omega_d * np.sin(omega_d * t)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"zeta debe ser mayor que 0.\")\n",
    "\n",
    "    return torch.tensor(x, dtype=torch.float32, device=device).view(-1, 1)\n",
    "\n",
    "# -------------------------------------------\n",
    "# solucion exacta\n",
    "t_eval_np = t_eval.detach().cpu().numpy().ravel()\n",
    "x = masa_resorte_general(t_eval_np, x0, v0, wn, zeta)\n",
    "\n",
    "# predicci√≥n de la PINN\n",
    "x_pred_pinn = x_pinn(t_eval)\n",
    "\n",
    "print(f'Relative error: {relative_l2_error(x_pred_pinn, x)}')\n",
    "\n",
    "plot_comparison(t_eval, x, x_pred_pinn, loss_values_pinn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicios**:\n",
    "1. Ajusta los valores de los par√°metros del sistema din√°mico y analiza su impacto en la convergencia de la PINN.\n",
    "2. Ajusta los valores de los par√°metros `lambdas` en la funci√≥n de p√©rdida para ambas redes y analiza su impacto.\n",
    "2. Modifica la tasa de aprendizaje (`learning_rate`) del optimizador y el n√∫mero de iteraciones de entrenamiento, y eval√∫a el efecto en el desempe√±o.\n",
    "3. Cambia el n√∫mero de capas ocultas (`hidden_layers`), neuronas y funciones de activaci√≥n de la red neuronal, y observa el impacto en los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preguntas**:\n",
    "\n",
    "1. **¬øC√≥mo se puede abordar el sobreajuste en las PINNs si el objetivo es aprender los operadores subyacentes del sistema f√≠sico?**  \n",
    "   <details>\n",
    "   <summary>Respuesta</summary>\n",
    "   El sobreajuste en las PINNs (Physics-Informed Neural Networks) es un tema ampliamente discutido. En el aprendizaje autom√°tico tradicional, el sobreajuste se asocia con la incapacidad de un modelo para generalizar a datos no vistos previamente, lo que afecta su capacidad para realizar predicciones precisas en nuevas entradas. Sin embargo, en el contexto de las PINNs, buscamos un comportamiento diferente: que la red neuronal funcione como un modelo surrogate de la soluci√≥n de las ecuaciones diferenciales que describen el sistema f√≠sico. En este caso, el sobreajuste no necesariamente es perjudicial, ya que queremos que la red reproduzca fielmente la soluci√≥n dentro del dominio especificado.\n",
    "\n",
    "   El desaf√≠o relacionado con la generalizaci√≥n en las PINNs surge cuando estas redes se eval√∫an en geometr√≠as m√°s complejas o diferentes de las que fueron utilizadas durante el entrenamiento. En tales casos, una PINN que est√© sobreajustada a una √∫nica geometr√≠a podr√≠a fallar al adaptarse a las nuevas configuraciones, comprometiendo su capacidad para generalizar y capturar las din√°micas f√≠sicas subyacentes en contextos m√°s diversos. Por ello, abordar el sobreajuste implica equilibrar la fidelidad al dominio original y la adaptabilidad a nuevas geometr√≠as o condiciones.\n",
    "   </details>\n",
    "\n",
    "\n",
    "2. **Qu√© ventajas ofrece el uso del MSE en la funci√≥n de p√©rdida, dado que este enfoque puede subestimar la soluci√≥n al no incorporar formulaciones integrales o variacionales**  \n",
    "   <details>\n",
    "   <summary>Respuesta</summary>\n",
    "   El uso del MSE como funci√≥n de p√©rdida proporciona una forma sencilla y computacionalmente eficiente de medir las diferencias puntuales entre las predicciones del modelo y los valores objetivo. Sin embargo, el MSE se centra √∫nicamente en puntos individuales, lo que puede limitar su capacidad para capturar el comportamiento global de la soluci√≥n, especialmente en dominios complejos. Al incorporar formulaciones integrales o variacionales, la funci√≥n de p√©rdida puede reflejar el comportamiento de la soluci√≥n en todo el dominio, mejorando potencialmente la precisi√≥n y estabilidad. A pesar de estas limitaciones, el MSE sigue siendo popular porque simplifica la implementaci√≥n y reduce los costos computacionales, lo que lo hace adecuado para muchas aplicaciones pr√°cticas.\n",
    "   </details>\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pinns-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
