{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCgpgtSqTbvP"
   },
   "source": [
    "# Redes Neuronales Artificiales (ANN) vs. Redes Neuronales Informadas por la Física (PINNs)\n",
    "\n",
    "**Autores:** Tabita Catalán, Tomás Banduc, David Ortiz y Francisco Sahli — 2025\n",
    "\n",
    "Accede al trabajo fundacional de las PINNs [aquí](https://www.sciencedirect.com/science/article/pii/S0021999118307125).\n",
    "\n",
    "### Introducción\n",
    "\n",
    "En la lección anterior se construyó una PINN básica siguiendo un esquema estructurado de seis pasos, aplicado a un sistema lineal clásico (masa–resorte–amortiguador) con solución analítica conocida. Ese ejercicio permitió introducir los conceptos fundamentales de las PINNs, así como el rol de la física en la función de pérdida.\n",
    "\n",
    "En esta segunda lección se amplía ese marco comparando directamente Redes Neuronales Artificiales (ANNs) y Redes Neuronales Informadas por la Física (PINNs). Mientras que las ANNs dependen exclusivamente de los datos para aprender una solución, las PINNs incorporan de forma explícita las ecuaciones gobernantes del sistema, lo que mejora la estabilidad, reduce la dependencia de grandes conjuntos de datos y aporta interpretabilidad física.\n",
    "\n",
    "La comparación se realiza sobre el modelo del péndulo oscilante, un sistema no lineal que representa un aumento natural de complejidad respecto al caso estudiado previamente.\n",
    "\n",
    "### Resumen de la Actividad\n",
    "\n",
    "En esta actividad se implementan dos aproximaciones para resolver el modelo matemático no lineal de un péndulo oscilante:\n",
    "\n",
    "- una Red Neuronal Artificial (ANN) entrenada únicamente a partir de datos,\n",
    "- y una Red Neuronal Informada por la Física (PINN), siguiendo los mismos seis pasos introducidos en la lección anterior.\n",
    "\n",
    "Este enfoque permite aislar y analizar el efecto de incorporar la física del sistema en la función de pérdida, comparando desempeño, estabilidad y capacidad de generalización entre ambos modelos.\n",
    "\n",
    "### Objetivos de la Actividad\n",
    "\n",
    "Al finalizar esta actividad, podrás:\n",
    "\n",
    "- Comprender las diferencias conceptuales y prácticas entre ANNs y PINNs.  \n",
    "- Analizar por qué las PINNs requieren menos datos y presentan mayor coherencia física.  \n",
    "- Implementar y entrenar ANNs y PINNs en PyTorch para un mismo problema.  \n",
    "- Evaluar el impacto de la física en la calidad de la solución aprendida.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7OpUDIRTbvR"
   },
   "source": [
    "## Modelo matemático para describir un péndulo oscilante\n",
    "\n",
    "Queremos resolver el problema matemático relacionado con el **péndulo oscilante** [(wiki)](https://en.wikipedia.org/wiki/Pendulum_(mechanics)):\n",
    "\n",
    "| ![GIF](../figures/Oscillating_pendulum.gif?raw=1) | <img src=\"../figures/Pendulum_gravity.svg?raw=1\" alt=\"Diagrama del proyecto\" width=\"300\"/> |\n",
    "|-------------------------------------------|-------------------------------------------|\n",
    "| Vectores de velocidad y aceleración del péndulo  | Diagrama de fuerzas |\n",
    "\n",
    "\n",
    "**Supuestos:**\n",
    "\n",
    "- La varilla es rígida y sin masa [(Tarea - el caso de una cuerda elástica)](https://en.wikipedia.org/wiki/Elastic_pendulum#:~:text=In%20physics%20and%20mathematics%2C%20in,%2Ddimensional%20spring%2Dmass%20system.).\n",
    "- El peso es una masa puntual.  \n",
    "- Dos dimensiones [(Tarea - una dimensión adicional de movimiento)](https://www.instagram.com/reel/CffUr64PjCx/?igsh=MWlmM2FscG9oYnp6bw%3D%3D).\n",
    "- No hay resistencia del aire [(Tarea - inmersión en un fluido)](https://www.youtube.com/watch?v=erveOJD_qv4&ab_channel=Lettherebemath).\n",
    "- El campo gravitacional es uniforme y el soporte no se mueve.\n",
    "\n",
    "Nos interesa encontrar el ángulo vertical $\\theta(t) \\in [0, 2\\pi)$ tal que:\n",
    "\n",
    "$$\n",
    "\\frac{d^2\\theta}{dt^2}+\\frac{g}{l}\\sin\\theta=0,\\quad\\theta(0)=\\theta_0,\\quad\\theta'(0)=0,\\quad t\\in\\mathbb{R},\n",
    "$$\n",
    "\n",
    "donde $g\\approx 9.81[m/s^2]$, $l$ es el largo de la varilla y $t$ la variable temporal.  \n",
    "\n",
    "**Repaso de conceptos de ecuaciones diferenciales:**\n",
    "\n",
    "- ¿Por qué esta es una ecuación diferencial no lineal? ¿Qué supuestos deberían hacerse para linealizar el modelo?\n",
    "- ¿Es una ecuación diferencial ordinaria (EDO) o una ecuación diferencial parcial (EDP)?  \n",
    "- ¿Cuál es el orden? ¿cuál es el grado?  \n",
    "\n",
    "Un método útil es convertir el modelo en un sistema acoplado de EDOs:  \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d\\theta}{dt} &= \\omega, \\quad \\text{(velocidad angular)}\\\\\n",
    "\\frac{d\\omega}{dt} & = -\\frac{g}{l}\\sin\\theta, \\quad \\text{(aceleración angular)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Flujo de Trabajo  \n",
    "1. Calcular la solución numérica del modelo no lineal del péndulo oscilante y preparación de los datos de entrenamiento añadiendo ruido, remuestreando y limitando el tiempo para simular un escenario real.  \n",
    "2. Definir el modelo ANN utilizando la arquitectura de PyTorch y entrenar con los datos preparados. Graficar la solución.  \n",
    "3. Definir el modelo PINN utilizando la arquitectura de PyTorch y entrenar con los datos preparados. Graficar la solución.  \n",
    "4. Comparar las soluciones obtenidas con ambas arquitecturas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gKS9hYYTbvS"
   },
   "source": [
    "## Configuración Inicial  \n",
    "\n",
    "Comenzamos importando algunos paquetes útiles y definiendo algunas funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvjIWMEtTbvS"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy for numerical operations\n",
    "import numpy as np\n",
    "# Import PyTorch for building and training neural networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Import Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "\n",
    "# Ignore Warning Messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLwL3oIbTbvS",
    "outputId": "d732db5c-47d7-4528-8888-d66be1381707"
   },
   "outputs": [],
   "source": [
    "# Setup (device + plots)\n",
    "def get_device() -> str:\n",
    "    return \"cuda\" if torch.cuda.is_available() else \\\n",
    "           \"mps\"  if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "def set_mpl_style(gray: str = \"#5c5c5c\") -> None:\n",
    "    mpl.rcParams.update({\n",
    "        \"image.cmap\": \"viridis\",\n",
    "        \"text.color\": gray, \"xtick.color\": gray, \"ytick.color\": gray,\n",
    "        \"axes.labelcolor\": gray, \"axes.edgecolor\": gray,\n",
    "        \"axes.spines.right\": False, \"axes.spines.top\": False,\n",
    "        \"axes.formatter.use_mathtext\": True, \"axes.unicode_minus\": False,\n",
    "        \"font.size\": 15, \"interactive\": False, \"font.family\": \"sans-serif\",\n",
    "        \"legend.loc\": \"best\", \"text.usetex\": False, \"mathtext.fontset\": \"stix\",\n",
    "    })\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using {device} device\")\n",
    "set_mpl_style()\n",
    "\n",
    "# Metrics\n",
    "def calculate_snr(signal, noise) -> float:\n",
    "    s, n = np.asarray(signal), np.asarray(noise)\n",
    "    return 10.0 * np.log10(np.mean(s**2) / np.mean(n**2))\n",
    "\n",
    "def relative_l2_error(u_num: torch.Tensor, u_ref: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.norm(u_num - u_ref) / torch.norm(u_ref)\n",
    "\n",
    "# Autodiff helper\n",
    "def grad(outputs: torch.Tensor, inputs: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"d(outputs)/d(inputs) with create_graph=True.\"\"\"\n",
    "    return torch.autograd.grad(\n",
    "        outputs, inputs,\n",
    "        grad_outputs=torch.ones_like(outputs),\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "# Plotting\n",
    "def plot_comparison(t: torch.Tensor, theta_true, theta_pred: torch.Tensor, loss) -> None:\n",
    "    t_np = t.detach().cpu().numpy().ravel()\n",
    "    pred_np = theta_pred.detach().cpu().numpy().ravel()\n",
    "    true_np = np.asarray(theta_true).ravel()\n",
    "    diff = np.abs(true_np - pred_np)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axs[0].plot(t_np, true_np, label=r'$\\theta(t)$ (numerical)')\n",
    "    axs[0].plot(t_np, pred_np, label=r'$\\theta_{\\mathrm{pred}}(t)$')\n",
    "    axs[0].set(title='Numerical vs Predicted', xlabel=r'Time $(s)$', \n",
    "               ylabel='Amplitude', ylim=(-1, 1.3))\n",
    "    axs[0].legend(frameon=False)\n",
    "\n",
    "    axs[1].plot(t_np, diff)\n",
    "    axs[1].set(title='Absolute Difference', xlabel=r'Time $(s)$', \n",
    "               ylabel=r'$|\\theta - \\theta_{\\mathrm{pred}}|$')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "    ax.plot(loss)\n",
    "    ax.set(title='Training Progress', xlabel='Iteration', \n",
    "           ylabel='Loss', xscale='log', yscale='log')\n",
    "    ax.grid(True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtSeOyujTbvT"
   },
   "source": [
    "## 1. Solución numérica del péndulo oscilante y preparación de los datos de entrenamiento\n",
    "El objetivo de esta etapa es simular la obtención de datos de un péndulo, considerando los supuestos previamente mencionados.\n",
    "\n",
    "### 1.1 Solución numérica\n",
    "Para la solución numérica utilizamos el método [Runge-Kutta de cuarto orden](https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods) de `scipy`. Comenzamos definiendo los parámetros para este ejemplo, el modelo del péndulo y el dominio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77rbOuBRTbvT"
   },
   "outputs": [],
   "source": [
    "g = 9.81  # gravity acceleration (m/s^2)\n",
    "L = 1.0   # Pendulum's rod length (m)\n",
    "theta0 = np.pi / 4  # Initial condition (Position in rads)\n",
    "omega0 = 0.0        # Initial angular speed (rad/s)\n",
    "sample_freq = 100   # sample rate 100Hz\n",
    "\n",
    "# Simulation time\n",
    "t_span = (0, 10)  # from 0 to 10 seconds\n",
    "t_eval = np.linspace(t_span[0], t_span[1], sample_freq*t_span[1])  # Points to be evaluated\n",
    "\n",
    "# We define the system of coupled ODEs\n",
    "def pendulum(t, y):\n",
    "    theta, omega = y\n",
    "    dtheta_dt = omega\n",
    "    domega_dt = -(g / L) * np.sin(theta)\n",
    "    return [dtheta_dt, domega_dt]\n",
    "\n",
    "# Initial conditions\n",
    "y0 = [theta0, omega0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csYieohwTbvU"
   },
   "source": [
    "Ahora resolvemos el problema numéricamente utilizando `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "5-DGSnPhTbvU",
    "outputId": "00acced0-2907-4e90-c1c0-73fc56d3c60d"
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# Solve the initial value problem using Runge-Kutta 4th order\n",
    "num_sol = solve_ivp(pendulum, t_span, y0, t_eval=t_eval, method='RK45')\n",
    "\n",
    "# We extract the solutions\n",
    "theta_num = num_sol.y[0]\n",
    "omega_num = num_sol.y[1]\n",
    "\n",
    "# We graph the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t_eval, theta_num, label=r'Angular Displacement $\\theta(t)[rad]$')\n",
    "plt.plot(t_eval, omega_num, label=r'Angular Velocity $\\omega(t)[rad/s]$')\n",
    "plt.xlabel(r'Time $[s]$')\n",
    "plt.ylim(-2.5,3.3)\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.title('Nonlinear Pendulum Solution')\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaZRsQHvTbvU"
   },
   "source": [
    "### 1.2. Preparación de los datos de entrenamiento  <a id='data_prep'></a>\n",
    "\n",
    "A continuación, consideramos la solución numérica como los **datos de entrenamiento** que provienen de las mediciones de un sensor. Añadimos ruido gaussiano, remuestreamos y recortamos los datos a $2.5$ s para evaluar el rendimiento de la ANN, simulando un escenario real. Además, calculamos la relación señal-ruido $SNR = 10\\log_{10} \\left(\\frac{P_{signal}}{P_{noise}}\\right)$, donde $P_{signal}$ y $P_{noise}$ son la potencia de la señal y del ruido, respectivamente, para determinar el nivel de distorsión en la señal. Finalmente, llamamos a los datos de entrenamiento con ruido $\\theta_{data}(t)$.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "agIihTIyTbvV",
    "outputId": "fd129006-9880-4b5c-cb8d-7ec2df27ca63"
   },
   "outputs": [],
   "source": [
    "# Add gaussian noise\n",
    "std_deviation = 0.05\n",
    "noise = np.random.normal(0,std_deviation,theta_num.shape[0])\n",
    "theta_noisy = theta_num + noise\n",
    "print(f'SNR: {calculate_snr(theta_noisy, noise):.4f} dB')\n",
    "\n",
    "# Resample and cut to 2.5s\n",
    "resample = 5          # resample\n",
    "cut_time = int(2.5*sample_freq)  # 2.5s times 100Hz\n",
    "\n",
    "theta_data = theta_noisy[:cut_time:resample]\n",
    "t_data = t_eval[:cut_time:resample]\n",
    "\n",
    "# We graph the observed data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t_eval, theta_num, label=r'Angular Displacement (model) $\\theta(t)$ ')\n",
    "plt.plot(t_data, theta_data, label=r'Training data (measures) $\\theta_{data}(t)$ ')\n",
    "plt.xlabel(r'Time $[s]$')\n",
    "plt.ylabel(r'Angular displacement $[rad]$')\n",
    "plt.ylim(-1,1.3)\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.title('Training data')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PpIuan2TbvV"
   },
   "source": [
    "## 2. Entrenando la Red Neuronal Artificial\n",
    "\n",
    "Entrenaremos la red neuronal artificial para aproximar directamente la solución de la ecuación diferencial, es decir,\n",
    "\n",
    "$$\n",
    "\\theta_{NN}(t; \\Theta) \\approx \\theta(t)\n",
    "$$\n",
    "\n",
    "donde $\\Theta$ son los parámetros entrenables de la ANN. Utilizaremos `PyTorch` para definir la red y la entrenaremos con el optimizador ADAM. Además, convertiremos el dominio temporal y las observaciones a `torch.tensors`. \n",
    "\n",
    "### Función de pérdida \n",
    "\n",
    "Para entrenar la ANN necesitamos datos y una función de pérdida. Nuestros datos serán observaciones ruidosas de la solución $\\theta_{data}(t)$, obtenidas en puntos de colocación $\\{t_i\\}_N$ elegidos del dominio. Utilizamos como función de pérdida el error cuadrático medio ($MSE$) entre estas observaciones y la evaluación de la ANN en los mismos puntos de colocación, es decir,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\Theta) := \\lambda_1 MSE(\\theta_{NN}(t; \\Theta), \\theta_{data}(t)) = \\frac{\\lambda_1}{N}\\sum_i (\\theta_{NN}(t_i; \\Theta) - \\theta_{data}(t_i))^2\n",
    "$$\n",
    "\n",
    "donde $\\lambda_1 \\in \\mathbb{R}^+$ es un peso positivo y $N$ es el número de muestras. El entrenamiento se realiza minimizando la función de pérdida $\\mathcal{L}(\\Theta)$, es decir,\n",
    "\n",
    "$$\n",
    "\\min_{\\Theta \\in \\mathbb{R}} \\mathcal{L}(\\Theta) \\rightarrow 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# ETAPA 1: DEFINICIÓN DE LOS PARÁMETROS (MODELO FÍSICO)\n",
    "#===============================================================================\n",
    "\n",
    "\n",
    "#===============================================================================\n",
    "# ETAPA 2: DEFINICIÓN DEL DOMINIO \n",
    "#===============================================================================\n",
    "\n",
    "\n",
    "#===============================================================================\n",
    "# ETAPA 3: CREACIÓN DE LA RED NEURONAL SURROGANTE \n",
    "#===============================================================================\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# ETAPA 5: DEFINICIÓN DE LA FUNCIÓN DE COSTO BASADA ÚNICAMENTE EN LOS DATOS\n",
    "#==========================================================================\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# ETAPA 6: DEFINICIÓN DEl OPTIMIZADOR\n",
    "#==========================================================================\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "# CICLO DE ENTRENAMIENTO\n",
    "#==========================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YzPb-nXTbvV"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# training parameters\n",
    "hidden_layers = [1, 50, 50, 50, 1]\n",
    "learning_rate = 0.001\n",
    "training_iter = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUUlUvTETbvV"
   },
   "outputs": [],
   "source": [
    "# Define a loss function (Mean Squared Error) for training the network\n",
    "MSE_func = nn.MSELoss()\n",
    "\n",
    "# Convert the NumPy arrays to PyTorch tensors and add an extra dimension\n",
    "# test time Numpy array to Pytorch tensor\n",
    "t_test = torch.tensor(t_eval, device=device, requires_grad=True).view(-1,1).float()\n",
    "# train time Numpy array to Pytorch tensor\n",
    "t_data = torch.tensor(t_data, device=device, requires_grad=True).view(-1,1).float()\n",
    "# Numerical theta to test Numpy array to pytorch tensor\n",
    "theta_test = torch.tensor(theta_num, device=device, requires_grad=True).view(-1,1).float()\n",
    "# Numerical theta to train Numpy array to pytorch tensor\n",
    "theta_data = torch.tensor(theta_data, device=device, requires_grad=True).view(-1,1).float()\n",
    "\n",
    "# Define a neural network class with user defined layers and neurons\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, hlayers):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(len(hlayers[:-2])):\n",
    "            layers.append(nn.Linear(hlayers[i], hlayers[i+1]))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(hlayers[-2], hlayers[-1]))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        \"\"\"Xavier Glorot parameter initialization of the Neural Network\n",
    "        \"\"\"\n",
    "        def init_normal(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight) # Xavier\n",
    "        self.apply(init_normal)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1XnbAucTbvV",
    "outputId": "157c08c8-fe8f-40dc-f9c9-8d85f04d9281"
   },
   "outputs": [],
   "source": [
    "# Create an instance of the neural network\n",
    "theta_ann = NeuralNetwork(hidden_layers).to(device)\n",
    "nparams = sum(p.numel() for p in theta_ann.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {nparams}')\n",
    "\n",
    "# Define an optimizer (Adam) for training the network\n",
    "optimizer = optim.Adam(theta_ann.parameters(), lr=learning_rate,\n",
    "                       betas= (0.99,0.999), eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbcXCC2CTbvW",
    "outputId": "74ad7d01-3a5b-45ff-b7ef-8a30db60cad5"
   },
   "outputs": [],
   "source": [
    "def NeuralNetworkLoss(forward_pass, t, theta_data, lambda1 = 1):\n",
    "\n",
    "    theta_nn = forward_pass(t)\n",
    "    data_loss = lambda1 * MSE_func(theta_nn, theta_data)\n",
    "\n",
    "    return  data_loss\n",
    "\n",
    "# Initialize a list to store the loss values\n",
    "loss_values_ann = []\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the neural network\n",
    "for i in range(training_iter):\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "\n",
    "    # input x and predict based on x\n",
    "    loss = NeuralNetworkLoss(theta_ann,\n",
    "                             t_data,\n",
    "                             theta_data)    # must be (1. nn output, 2. target)\n",
    "\n",
    "    # Append the current loss value to the list\n",
    "    loss_values_ann.append(loss.item())\n",
    "\n",
    "    if i % 1000 == 0:  # print every 100 iterations\n",
    "        print(f\"Iteration {i}: Loss {loss.item()}\")\n",
    "\n",
    "    loss.backward() # compute gradients (backpropagation)\n",
    "    optimizer.step() # update the ANN weigths\n",
    "\n",
    "# Stop the timer and calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training time: {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sITbWTKXTbvW"
   },
   "source": [
    "graficamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "53BRPDdjTbvX",
    "outputId": "febce2b5-b3bf-418d-8cf5-d9129a792ede"
   },
   "outputs": [],
   "source": [
    "theta_pred_ann = theta_ann(t_test).to(device)\n",
    "\n",
    "print(f'Relative error: {relative_l2_error(theta_pred_ann, theta_test)}')\n",
    "\n",
    "plot_comparison(t_test, theta_num, theta_pred_ann, loss_values_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bE2S96IyTbvX"
   },
   "source": [
    "## 4. Entrenando la Red Neuronal Informada por Física (PINN)\n",
    "\n",
    "Ahora queremos entrenar una PINN de para aproximar la solución de la EDO,\n",
    "\n",
    "$$\n",
    "\\theta_{PINN}(t; \\Theta) \\approx \\theta(t).\n",
    "$$\n",
    "\n",
    "Esta PINN tendrá la misma arquitectura que la ANN que usamos anteriormente, pero esta vez la entrenaremos incorporando la física del problema además de las observaciones. Usaremos las mismas observaciones ruidosas (**datos de entrenamiento**) que antes, pero también incluiremos las ecuaciones que describen el comportamiento de las derivadas de la solución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7_P7E9vTbvX",
    "outputId": "72567b58-3028-4dca-c961-95ce3a1519c6"
   },
   "outputs": [],
   "source": [
    "# Create an instance of the neural network\n",
    "theta_pinn = NeuralNetwork(hidden_layers).to(device)\n",
    "nparams = sum(p.numel() for p in theta_pinn.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {nparams}')\n",
    "\n",
    "# Define an optimizer (Adam) for training the network\n",
    "optimizer = optim.Adam(theta_pinn.parameters(), lr=learning_rate,\n",
    "                       betas= (0.99,0.999), eps = 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wS25mOJTbvX"
   },
   "source": [
    "### Función de pérdida informada por la física del problema\n",
    "\n",
    "Para entrenar la PINN, recordemos el modelo del péndulo y definamos las funciones $f_{ode}(t;g,l)$, $g_{ic}(0)$ y $h_{bc}(0)$ para la ODE, la condición inicial y la condición de frontera. Además, reemplazamos la solución analítica $\\theta(t)$ con la salida de la PINN $\\theta_{pinn}(t; \\Theta)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f_{ode}(t;\\theta_{pinn}):=&\\frac{d^2\\theta_{PINN}(t; \\Theta)}{dt^2}+\\frac{g}{l}\\sin(\\theta_{pinn}(t; \\Theta)) = 0\\\\\n",
    "g_{ic}(0;\\theta_{pinn}):=&\\theta_{pinn}(0; \\Theta) = \\theta_0\\\\\n",
    "h_{bc}(0;\\theta_{pinn}):=&\\theta_{pinn}'(0; \\Theta) = 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Nuevamente utilizamos el $MSE$ y definimos la función de pérdida informada por física:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta):= &\\frac{\\lambda_1}{N}\\sum_i\\left(f_{ode}(t_i;\\theta_{pinn})-0\\right)^2 \\quad \\text{Pérdida de la ODE}\\\\\n",
    "                   & + \\lambda_2 (g_{ic}(0;\\theta_{pinn})-\\theta_0)^2 \\quad \\text{Pérdida de la condición inicial IC}\\\\\n",
    "                   & + \\lambda_3 (h_{bc}(0;\\theta_{pinn})-0)^2 \\quad \\text{Pérdida de la condición de frontera BC}\\\\\n",
    "                   & + \\frac{\\lambda_4}{N}\\sum_i (\\theta_{pinn}(t_i; \\Theta) - \\theta_{data}(t_i))^2 \\quad \\text{Pérdida de los datos (DATA)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "donde $\\lambda_{1,2,3,4}\\in\\mathbb{R}^+$ son pesos positivos y $N$ es el número de muestras. \n",
    "\n",
    "<div class=\"alert alert-info\"\n",
    "    style=\"background-color:#5c5c5c;color:#000000;border-color:#000000\">\n",
    "  <strong>REMARK!</strong> Cuando no incluimos la función de pérdida relacionada con los datos, estamos empleando un esquema independiente de datos (*data-free*); cuando incluimos los datos, estamos empleando un esquema impulsado por datos (*data-driven*).\n",
    "</div>\n",
    "\n",
    "El entrenamiento se realiza minimizando la función de pérdida $\\mathcal{L}(\\Theta)$, es decir,\n",
    "\n",
    "$$\n",
    "\\min_{\\Theta\\in\\mathbb{R}} \\mathcal{L}(\\Theta)\\rightarrow 0\n",
    "$$\n",
    "\n",
    "<div class=\"alert alert-info\"\n",
    "    style=\"background-color:#5c5c5c;color:#000000;border-color:#000000\">\n",
    "  <strong>REMARK!</strong> La diferenciación automática (`torch.autograd`) es una herramienta poderosa para calcular los gradientes de la PINN con respecto a la entrada, lo que será útil para evaluar la función de pérdida. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlUB-YF3TbvY",
    "outputId": "223a5d0a-051e-4353-99e6-ac08220e85f3"
   },
   "outputs": [],
   "source": [
    "# Define t = 0 for boundary an initial conditions\n",
    "t0 = torch.tensor(0., device=device, requires_grad=True).view(-1,1)\n",
    "\n",
    "# HINT: use grad funtion (a wraper for torch.autograd) to calculate the\n",
    "# derivatives of the ANN\n",
    "def PINNLoss(forward_pass, t_phys, t_data, theta_data, \n",
    "             lambda1 = 1, lambda2 = 1, lambda3 = 1, lambda4 = 1):\n",
    "\n",
    "    # ANN output, first and second derivatives\n",
    "    theta_pinn1 = forward_pass(t_phys)\n",
    "    theta_pinn_dt = grad(theta_pinn1, t_phys)\n",
    "    theta_pinn_ddt = grad(theta_pinn_dt, t_phys)\n",
    "    \n",
    "    f_ode = theta_pinn_ddt + (g/L) * torch.sin(theta_pinn1)\n",
    "    ODE_loss = lambda1 * MSE_func(f_ode, torch.zeros_like(f_ode)) \n",
    "    \n",
    "    g_ic = forward_pass(t0)\n",
    "    IC_loss = lambda2 * MSE_func(g_ic, torch.ones_like(g_ic)*theta0)\n",
    "    \n",
    "    h_bc = grad(forward_pass(t0),t0)\n",
    "    BC_loss = lambda3 * MSE_func(h_bc, torch.zeros_like(h_bc))\n",
    "    \n",
    "    theta_nn2 = forward_pass(t_data)\n",
    "    data_loss = lambda4 * MSE_func(theta_nn2, theta_data)\n",
    "    \n",
    "    return ODE_loss + IC_loss + BC_loss + data_loss\n",
    "\n",
    "# Initialize a list to store the loss values\n",
    "loss_values_pinn = []\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Training the neural network\n",
    "for i in range(training_iter):\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "\n",
    "    # input x and predict based on x\n",
    "    loss = PINNLoss(theta_pinn, t_test, t_data, theta_data)\n",
    "\n",
    "    # Append the current loss value to the list\n",
    "    loss_values_pinn.append(loss.item())\n",
    "\n",
    "    if i % 1000 == 0:  # print every 100 iterations\n",
    "        print(f\"Iteration {i}: Loss {loss.item()}\")\n",
    "\n",
    "    loss.backward() # compute gradients (backpropagation)\n",
    "    optimizer.step() # update the ANN weigths\n",
    "\n",
    "# Stop the timer and calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G70N-xiTbvY"
   },
   "source": [
    "Nuevamente, graficamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "sLEu3EJbTbvY",
    "outputId": "391ca19f-ebdf-4b56-ea72-ab9d4512646d"
   },
   "outputs": [],
   "source": [
    "theta_pred_pinn = theta_pinn(t_test)\n",
    "\n",
    "print(f'Relative error: {relative_l2_error(theta_pred_pinn, theta_test)}')\n",
    "\n",
    "plot_comparison(t_test, theta_num, theta_pred_pinn, loss_values_pinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3DZxHeBTbvY"
   },
   "source": [
    "## 5. Comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "z1e1kIGaTbvZ",
    "outputId": "ac388224-0634-4895-b5f4-1aba257b94bf"
   },
   "outputs": [],
   "source": [
    "plot_comparison(t_test, theta_num, theta_pred_ann, loss_values_ann)\n",
    "plot_comparison(t_test, theta_num, theta_pred_pinn, loss_values_pinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfSHJ_0hTbvZ"
   },
   "source": [
    "## **Ejercicios**:\n",
    "\n",
    "1. Elimina la pérdida de los datos del entrenamiento de la PINN. ¿Aún se puede obtener la solución?\n",
    "2. Incrementa y reduce el parámetro `std_deviation` en la sección [Preparación de los datos de entrenamiento](#data_prep) para cambiar el `SNR`. También cambia las variables `resample` y `ctime`, y compara los resultados tras entrenar la ANN y la PINN.\n",
    "3. Ajusta los valores de los parámetros `lambdas` en la función de pérdida para ambas redes y analiza su impacto.\n",
    "4. Modifica la tasa de aprendizaje (`learning_rate`) del optimizador y el número de iteraciones de entrenamiento, y evalúa el efecto en el desempeño.\n",
    "5. Cambia el número de capas ocultas (`hidden_layers`), neuronas y funciones de activación de la red neuronal, y observa el impacto en los resultados.\n",
    "\n",
    "## **Preguntas**:\n",
    "\n",
    "1. **¿Cómo se puede abordar el sobreajuste en las PINNs si el objetivo es aprender los operadores subyacentes del sistema físico?**  \n",
    "   <details>\n",
    "   <summary>Respuesta</summary>\n",
    "   El sobreajuste en las PINNs (Physics-Informed Neural Networks) es un tema ampliamente discutido. En el aprendizaje automático tradicional, el sobreajuste se asocia con la incapacidad de un modelo para generalizar a datos no vistos previamente, lo que afecta su capacidad para realizar predicciones precisas en nuevas entradas. Sin embargo, en el contexto de las PINNs, buscamos un comportamiento diferente: que la red neuronal funcione como un modelo surrogate de la solución de las ecuaciones diferenciales que describen el sistema físico. En este caso, el sobreajuste no necesariamente es perjudicial, ya que queremos que la red reproduzca fielmente la solución dentro del dominio especificado.\n",
    "\n",
    "   El desafío relacionado con la generalización en las PINNs surge cuando estas redes se evalúan en geometrías más complejas o diferentes de las que fueron utilizadas durante el entrenamiento. En tales casos, una PINN que esté sobreajustada a una única geometría podría fallar al adaptarse a las nuevas configuraciones, comprometiendo su capacidad para generalizar y capturar las dinámicas físicas subyacentes en contextos más diversos. Por ello, abordar el sobreajuste implica equilibrar la fidelidad al dominio original y la adaptabilidad a nuevas geometrías o condiciones.\n",
    "   </details>\n",
    "\n",
    "\n",
    "2. **Qué ventajas ofrece el uso del MSE en la función de pérdida, dado que este enfoque puede subestimar la solución al no incorporar formulaciones integrales o variacionales**  \n",
    "   <details>\n",
    "   <summary>Respuesta</summary>\n",
    "   El uso del MSE como función de pérdida proporciona una forma sencilla y computacionalmente eficiente de medir las diferencias puntuales entre las predicciones del modelo y los valores objetivo. Sin embargo, el MSE se centra únicamente en puntos individuales, lo que puede limitar su capacidad para capturar el comportamiento global de la solución, especialmente en dominios complejos. Al incorporar formulaciones integrales o variacionales, la función de pérdida puede reflejar el comportamiento de la solución en todo el dominio, mejorando potencialmente la precisión y estabilidad. A pesar de estas limitaciones, el MSE sigue siendo popular porque simplifica la implementación y reduce los costos computacionales, lo que lo hace adecuado para muchas aplicaciones prácticas.\n",
    "   </details>\n",
    "\n",
    "\n",
    "3. **¿En qué formas son ventajosas las PINNs comparadas con los métodos numéricos tradicionales, considerando el mayor tiempo requerido para el entrenamiento?**  \n",
    "   <details>\n",
    "   <summary>Respuesta</summary>\n",
    "   Las PINNs ofrecen varias ventajas frente a los métodos numéricos tradicionales, a pesar de su tiempo de entrenamiento generalmente más largo. Una ventaja clave es su flexibilidad para manejar dominios complejos, de alta dimensionalidad y geometrías irregulares sin requerir mallas estructuradas. Las PINNs también pueden incorporar fácilmente restricciones o datos adicionales, como mediciones experimentales o condiciones de frontera. A diferencia de muchos métodos numéricos, una vez entrenadas, las PINNs generalizan bien a diferentes condiciones iniciales y de frontera, lo que puede hacerlas más versátiles en escenarios que requieren simulaciones repetidas o ajustes de parámetros. Esta flexibilidad y adaptabilidad las convierten en una herramienta poderosa para ciertas tareas de modelado informadas por física donde los métodos tradicionales pueden estar limitados.\n",
    "   </details>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
